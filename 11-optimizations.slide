Интересни имплементационни детайли в Go
04.12.2014

fmi@golang.bg
http://fmi.golang.bg/
@fmi_golang


* Как работи компилаторът на Go?

gc toolchain-а наследява този на plan9

Туловете в него са от типа `\d[acl]`:

- 5c, 6c и 8c са C компилатори за arm, amd64 и 386
- 5a, 6a и 8a са асемблери за arm, amd64 и 386
- 5l, 6l и 8l са линкъри за arm, amd64 и 386

И къде тук има go?

- 5g, 6g, 8g :)


* go build

-x го кара да принтира какво всъщност прави:

	-> go build -x github.com/Vladimiroff/vec2d
	WORK=/var/folders/t2/24j0lkxs1d93btzxnl71n_kw0000gn/T/go-build703616983
	mkdir -p $WORK/github.com/Vladimiroff/vec2d/_obj/
	mkdir -p $WORK/github.com/Vladimiroff/
	cd /Users/kiril/go/src/github.com/Vladimiroff/vec2d
	/usr/local/Cellar/go/1.3.3/libexec/pkg/tool/darwin_amd64/6g
		-o $WORK/github.com/Vladimiroff/vec2d.a -trimpath $WORK
		-p github.com/Vladimiroff/vec2d -complete
		-D _/Users/kiril/go/src/github.com/Vladimiroff/vec2d -I $WORK
		-pack ./utils.go ./vector.go

* Стойности

    var gopher int32 = 2014

- Обикновена стойност
- Заема точно 4 байта
- В Python са 24
- В Java са 4, докато не решите да го сложите в List или Map
- В Go винаги можем да определим големината на нещо


* CPU Cache

	type Location struct {
		// float64 -> 8 bytes
		X, Y, Z float64
		// 24 bytes in total
	}

	var Locations [1000]Location
	// 24 * 1000 bytes stored *sequnetially*

- Структурите са компактни
- Без излишна индирекция

=> По-добро използване на кеша


* Извикване на функция

- Създава се нов стек фрейм
- Записан е return адресът на този, който е извикал функцията
- Всеки регистър, в който се пише от тази функция, трябва да бъде запазен предварително
- Смята се адресът на функцията и се изпълнява

Бе върши се доста работа по темата.


* Пример

	package util

	func Max(a, b int) int {
		if a > b {
			return a
		}
		return b
	}

---

	package main

	func double(a, b int) int {
		return 2 * util.Max(a, b)
	}


* Inlining

	package main

	func double(a, b int) int {
		max := b
		if a > b {
			max = a
		}
		return 2 * max
	}


* Dead code elimination

- Тривиална оптимизация, която прави компилаторът
- Недостъпни парчета изобщо не биват компилирани

	func LargeAndComplicatedAction() {
		if false {
			[...]
		}
		[...]
	}

- Да, де, ама колко често правим такива неща?

* Debug checks


	func DebugChecks() bool {
		return debugBuildTagIsOn
	}

	func LargeAndComplicatedAction() {
		if DebugChecks() {
			[...]
		}
		[...]
	}

- Това изглежда адекватно, ама сега компилаторът не може да е сигурен, че това е "мъртъв" код
- Inlining :)

* Escape analysis

- stack vs. heap

Кое къде отива в С, примерно?

- дефинирана променлива в скоупа на функция отива на стека
- `malloc` отива на хийпа

Толкова е просто. Хайде сега на Go


* Stupid Sum

.code code/11/esc.go /BEGIN Sum/,/END Sum/

- Къде отива `numbers`?


* Cursor

.code code/11/esc.go /type/,/BEGIN Sum/

- Къде отива `new(Cursor)`?

* Компилаторът на Go е комуникативно същество

	-> go build -gcflags=-m esc.go
	# command-line-arguments
	./esc.go:9: can inline Center
	./esc.go:16: inlining call to Center
	./esc.go:9: Center c does not escape
	./esc.go:15: CenterCursor new(Cursor) does not escape
	./esc.go:22: SumFirst100 make([]int, 100) does not escape


* Да си поговорим за горутини

- Цял семестър ви обясняваме колко са малки, бързи и евтини за създаване.
- Нека ги разгледаме отвътре

Cooperatively scheduled

- chan send/receive
- go ...()
- syscall
- gc

* Cooperatively scheduled

.image http://dave.cheney.net/wp-content/uploads/2014/06/Gocon-2014-35.jpg


* Да си поговорим за C

Сценарий: Изпълняваме thread на C.

- Стандартната библиотека ще алокира памет за него
- Ще съобщи на kernel-а за нея
- От тук приема, че вече kernel-а знае какво да прави с тази памет
- Всичко е песен


* Unless...

        int ack(int m, int n)
        {
                if (m == 0) {
                        return n + 1;
                } else if (m > 0 && n == 0) {
                        return ack(m - 1, 1);
                } else {
                        return ack(m - 1, ack(m, n - 1));
                }
        }

        ack(4, 5);
        // segmentation fault

Рекурсия. Свърши ни паметта на стека.


* Как можем да го решим това?

- Да заделяме по-голям стек за всяка функция
Да, това ще понася по-дълбока рекурсия, но пък ще заделяме повече памет за
АБСОЛЮТНО всяка функция, която тя може да не използва.

- Да вземаме решение колко голям да бъде стекът
Ще знаем точно колко голям стек да заделяме за всяка функция, но този анализ ще
отнема време, което води до бавна компилация с много налучкване или бавно
изпълнение на всяка функция


* Адресно пространство

.image http://dave.cheney.net/wp-content/uploads/2014/06/Gocon-2014-39.jpg


* Guard page

.image http://dave.cheney.net/wp-content/uploads/2014/06/Gocon-2014-40.jpg


* Thread stacks and guard pages

.image http://dave.cheney.net/wp-content/uploads/2014/06/Gocon-2014-41.jpg


* Segmented Stacks

Това е начинът, по който Go до версия 1.3 управляваше стековете.

- При създаване на горутина се заделя 8kb и тя работи с тях
- Става интересно, когато те свършат
- Няма Guard page-ове
- При всяко влизане във функция се прави проверка, дали стекът е запълнен
- Ако това е така и все още има свободна памет, извиква `morestack`
- `morestack` заделя нова памет за стек
- На дъното на новия стек заделя една структура с информация за стария стек (включително адресът му)
- Рестартира последната функция, която е запълнила стека


* Stack Split

        +---------------+
        |               |
        |   unused      |
        |   stack       |
        |   space       |
        +---------------+
        |    Foobar     |
        |               |
        +---------------+       +---------------+
        |               |   +-->|    Foobar     |
        |  lessstack    |   |   |               |
        +---------------+   |   +---------------+
        | Stack info    |---+   | rest of stack |
        |               |       |               |
        +---------------+       +---------------+


* lessstsack

- Функция, която стои заложена, в края на стека
- Когато стигнем до нея, чете информацията за предния стек
- Намества стек пойнтъра към предишния сегмент
- След това спокойно можем да деалокираме този нов стек


* Супер яко, нали?

- Нямаме максимален размер на стека
- Което ни дава възможността всяка горутина да е с максимално малък стек
- Това е едно от нещата, което прави стартирането на нови горутини евтино
- Горутините, които порастнат твърде много се грижат да почистят след себе си

Но има и проблеми

- Деалокиране на стек е скъпа операция


* Stack copying

- Почти като сегментираните стекове, но не прави нов с информация за стария
- Вместо това прави нов *двойно*по-голям* стек и копира първия в него
- Старият стек вече може да бъде затрит
- Ако новият случайно намалее, няма нужда да правим нищо
- Ако той пак порастне, отново няма нужда да правим нищо


* Channels on steroids

В началото на тази година Dmitry Vyukov предложи редица оптимизации на каналите:

- make single-threaded (non-contended) channel operations faster
- make contended buffered (producer/consumer) channel operations faster
- make non-blocking failing operations (e.g. checking of "stop" channel) faster
- make chan semaphores (chan struct{}) faster
- make select statements faster


* Как?

Отдолу каналите са три вида:

1. Sync channels
2. Async channels
3. Async channels with zero-sized elements

* Sync channels

	struct Hchan {
		Lock;
		bool closed;
		SudoG* sendq;  // waiting senders
		SudoG* recvq;  // waiting receivers
	};

- Изпращането на стойност lock-ва, освен ако каналът не е затворен или получава от празен канал


* Async channel

	truct Hchan {
		uint32 cap;   // channel capacity
		Elem*  buf;   // ring buffer of size cap
		// send and receive positions,
		// low 32 bits represent position in the buffer,
		// high 32 bits represent the current “lap” over the ring buffer
		uint64 sendx;
		uint64 recvx;
	};

	struct Elem {
		// current lap,
		// the element is ready for writing on laps 0, 2, 4, ...
		// for reading -- on laps 1, 3, 5, ...
		uint32 lap;
		T val;  // user data
	};

- Няма lock, ако не си играе с wait queues (които си имат mutex-и)

* Async channels with zero-sized elements

Почти като обикновените async channels:

- операциите в него не са блокиращи
- чакането от опашки също е защитено от mutex

С тази разлика, че:

- Няма ring buffer-и за пращане и получаване, а просто един брояч
- Неблокиращите send и receive се оправят с брояча
- Проверката дали каналът е пълен или празен също просто проверява брояча


* Close

- Заключва mutex-a
- Вдига `closed` флага
- Отключва mutex-a


* Select

Не се опитва да хване всички mutex-и на всички канали

- Shuffle-ва каналите
- Проверява ги един по един, дали някой от тях е готов. Това *НЕ* налага хващане на mutex
- Ако вече има готови, дори не проверява останалите. Чак тогава трябва да хване lock-a да вземе стойността и да приключи
- В противен случвай, едва тогава се опитва да асинхронно да хване mutex-a на всеки канал и започва отначало
